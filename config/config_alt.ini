[vnds_dataset]
src_max_length = 1024
tgt_max_length = 256
data_dir = ./data/vnds
train_path = ./data/vnds/train.json
test_path = ./data/vnds/test.json
valid_path = ./data/vnds/val.json

[bill_sum_dataset]
src_max_length = 1024
tgt_max_length = 256
data_dir = ./data/bill_sum/
train_path = ./data/bill_sum/train.json
valid_path = ./data/bill_sum/val.json
us_test_path = ./data/bill_sum/us_test.json
ca_test_path = ./data/bill_sum/ca_test.json

[reddit_tifu_dataset]
src_max_length = 768
tgt_max_length = 40
long_dir = ./data/reddit_tifu/long/
short_dir = ./data/reddit_tifu/short/
train_path = train.json
test_path = test.json
valid_path = val.json

[vinewsqa_dataset]
src_max_length = 1024
tgt_max_length = 128
data_dir = ./data/ViNewsQA
train_path = ./data/ViNewsQA/train.json
test_path = ./data/ViNewsQA/test.json
valid_path = ./data/ViNewsQA/val.json

[viquad_dataset]
src_max_length = 1024
tgt_max_length = 128
data_dir = ./data/ViQuADv1.1
train_path = ./data/ViQuADv1.1/train.json
test_path = ./data/ViQuADv1.1/test.json
valid_path = ./data/ViQuADv1.1/val.json

[model-base]
sent_rep_tokens = True
pooler_dropout = 0.2
dropout_prop = 0.1
nhead = 8
num_layers = 2
n_classes = 1

[bart-sum]
pre_trained_name = facebook/bart-base
ffn_dim = 3072

[t5-sum]
pre_trained_name = t5-base
ffn_dim = 3072

[vit5-sum]
pre_trained_name = VietAI/vit5-base
ffn_dim = 3072

[bartpho-sum]
pre_trained_name = vinai/bartpho-syllable-base
ffn_dim = 3072

[pegasus-sum]
pre_trained_name = google/pegasus-large
ffn_dim = 4096

[trainer-base]
accelerator = gpu
accumulate_grad_batches = 8
amp_backend = native
auto_lr_find = False
auto_scale_batch_size = False
auto_select_gpus = False
default_root_dir = ./checkpoint
delta = 1.0e-5
devices = 1
enable_model_summary = True
enable_checkpointing = True
enable_progess_bar = True
eval_steps = 64
factor_test_size = 2
gradient_clip_val = 0.5
monitor = val_loss
log_every_n_steps = 256
losses = BCEWithLogitsLoss,CrossEntropyLoss
max_epochs = 20
n_losses = 2
no_decay = bias,LayerNorm.weight,layer_norm.weight,layernorm_embedding.weight,final_layer_norm.weight,self_attn_layer_norm.weight
num_beams = 4
num_workers = 4
patience = 5
precision = 16
save_on_train_epoch_end = True
save_top_k = 3
warmup_ratio = 0.01
weight_decay = 0.015

[pegasus-sum-trainer-reddit_tifu]
accumulate_grad_batches = 8
batch_size = 2
checkpoint = ./checkpoint/pegasus-sum-reddit/
max_epochs = 20
log = ./log/pegasus-sum-reddit/
lr = 1e-4
num_freeze_layers = 15
best_checkpoint = ./checkpoint/pegasus-sum-reddit/ckpt7.pt

[bart-sum-trainer-reddit_tifu]
accumulate_grad_batches = 8
batch_size = 8
checkpoint = ./checkpoint/bart-sum-reddit/
max_epochs = 20
log = ./log/bart-sum-reddit/
lr = 1e-4
num_freeze_layers = 5
best_checkpoint = ./

[bart-sum-trainer-bill_sum]
accumulate_grad_batches = 1
batch_size = 16
checkpoint = ./checkpoint/bart-sum-bill/
max_epochs = 30
log = ./log/bart-sum-bill/
lr = 1e-4
num_freeze_layers = 5
best_checkpoint = ./checkpoint/bart-sum-bill/ckpt13.pt

[t5-sum-trainer-reddit_tifu]
accumulate_grad_batches = 8
batch_size = 2
checkpoint = ./checkpoint/t5-sum-reddit/
max_epochs = 20
log = ./log/t5-sum-reddit/
lr = 1e-5
num_freeze_layers = 10
best_checkpoint = ./

[t5-sum-trainer-bill_sum]
accumulate_grad_batches = 1
batch_size = 16
checkpoint = ./checkpoint/t5-sum-bill/
max_epochs = 30
log = ./log/t5-sum-bill/
lr = 1e-4
num_freeze_layers = 10
best_checkpoint = ./checkpoint/t5-sum-bill/ckpt9.pt

[bartpho-sum-trainer-vnds]
accumulate_grad_batches = 16
batch_size = 2
checkpoint = ./checkpoint/bartpho-sum-vnds/
max_epochs = 20
log = ./log/bartpho-sum-vnds/
lr = 3e-4
num_freeze_layers = 5
best_checkpoint = ./

[vit5-sum-trainer-vnds]
accumulate_grad_batches = 64
batch_size = 1
checkpoint = ./checkpoint/vit5-sum-vnds/
eval_steps = 256
max_epochs = 30
log = ./log/vit5-sum-vnds/
lr = 5e-4
num_freeze_layers = 11
best_checkpoint = ./checkpoint/vit5-sum-vnds/ckpt24.pt

[bartpho-sum-trainer-vinewsqa]
accumulate_grad_batches = 2
batch_size = 8
checkpoint = ./checkpoint/bartpho-sum-vinewsqa/
max_epochs = 30
log = ./log/bartpho-sum-vinewsqa/
lr = 2e-5
num_freeze_layers = 5
best_checkpoint = ./checkpoint/bartpho-sum-vinewsqa/ckpt10.pt

[vit5-sum-trainer-vinewsqa]
accumulate_grad_batches = 2
batch_size = 8
checkpoint = ./checkpoint/vit5-sum-vinewsqa/
max_epochs = 30
log = ./log/vit5-sum-vinewsqa/
lr = 2e-5
num_freeze_layers = 11
best_checkpoint = ./checkpoint/vit5-sum-vinewsqa/ckpt5.pt

[bartpho-sum-trainer-viquad]
accumulate_grad_batches = 2
batch_size = 8
checkpoint = ./checkpoint/bartpho-sum-viquad/
max_epochs = 30
log = ./log/bartpho-sum-viquad/
lr = 2e-5
num_freeze_layers = 5
best_checkpoint = ./checkpoint/bartpho-sum-viquad/ckpt7.pt

[vit5-sum-trainer-viquad]
accumulate_grad_batches = 2
batch_size = 8
checkpoint = ./checkpoint/vit5-sum-viquad/
max_epochs = 30
log = ./log/vit5-sum-viquad/
lr = 2e-5
num_freeze_layers = 11
best_checkpoint = ./checkpoint/vit5-sum-viquad/ckpt13.pt

